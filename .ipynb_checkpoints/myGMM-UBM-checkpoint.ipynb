{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.fftpack import dct\n",
    "\n",
    "sns.set()\n",
    "import os\n",
    "import scipy\n",
    "import librosa.display\n",
    "from IPython.display import Audio\n",
    "import random\n",
    "from functools import reduce\n",
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract MFCC Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_rate = 48000\n",
    "def extractMFCC(filename, sample_rate):\n",
    "    #sample_rate = 192000\n",
    "    utter_part, sr = librosa.core.load(filename, sample_rate)  # load utterance audio\n",
    "    intervals = librosa.effects.split(utter_part, top_db=30)  # voice activity detection\n",
    "    # print(intervals)\n",
    "    S_total = []\n",
    "    for inte in intervals:\n",
    "        S = librosa.core.stft(y=utter_part[inte[0]:inte[1]])\n",
    "        S = np.abs(S) ** 2\n",
    "        # print(\"Size of S is {}\".format(S.shape))\n",
    "        mel_basis = librosa.filters.mel(sr=sample_rate, n_fft=2048, n_mels=40)\n",
    "        S = np.log10(np.dot(mel_basis, S) + 1e-6)\n",
    "        # print(S.shape)\n",
    "        S_total.append(S)\n",
    "    # plt.show()\n",
    "    # plt.pause(2)\n",
    "    # Extract MFCC feature\n",
    "    # mfccs = librosa.feature.mfcc(y=utter_part.astype('float'), sr=sample_rate, n_mfcc=10)\n",
    "    S_total = np.concatenate(S_total,axis=1)\n",
    "    # print(S_total.shape)\n",
    "    mfccs = librosa.feature.mfcc(S = S_total, sr=sample_rate, n_mfcc=40) # (128, times)\n",
    "    # print(mfccs.shape)\n",
    "    mfccs = mfccs.reshape(-1,40)\n",
    "    return mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [dirs for dirs in os.listdir('.') if(dirs[-4:]==(\"high\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hanqing-high', 'jianzhi-high', 'liuli-high', 'Nick-high', 'xiao-high']"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# Random select 2 as enrollment, to train GMM model\n",
    "def split(speaker_wavs):\n",
    "    random.shuffle(speaker_wavs)\n",
    "    # print(speaker_wavs)\n",
    "    enroll = speaker_wavs[:2]\n",
    "    verify = speaker_wavs[2:]\n",
    "    return enroll, verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers_en = {}\n",
    "speakers_ve = {}\n",
    "for idx,speaker in enumerate(dataset):\n",
    "    speaker_wavs = os.listdir(os.path.join('.', dataset[idx]))\n",
    "    speaker_label = dataset[idx][:-5]\n",
    "    enroll, verify = split(speaker_wavs)\n",
    "    en_mfccs = []\n",
    "    ve_mfccs = []\n",
    "    for en in enroll:\n",
    "        wav_path = os.path.join('.', dataset[idx], en)\n",
    "        mfcc = extractMFCC(wav_path,192000)\n",
    "        mfcc = mfcc - np.mean(mfcc, axis=0)\n",
    "        # print(mfcc.shape)\n",
    "        en_mfccs.append(mfcc)\n",
    "    speakers_en[speaker_label] = np.concatenate(en_mfccs, axis=0)\n",
    "    for ve in verify:\n",
    "        wav_path = os.path.join('.', dataset[idx], ve)\n",
    "        mfcc = extractMFCC(wav_path,192000)\n",
    "        mfcc = mfcc - np.mean(mfcc, axis=0)\n",
    "        # print(mfcc.shape)\n",
    "        ve_mfccs.append(mfcc)\n",
    "    speakers_ve[speaker_label] = np.concatenate(ve_mfccs, axis=0)\n",
    "#print(speakers_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1504, 40)\n",
      "(979, 40)\n",
      "(1504, 40)\n",
      "(1377, 40)\n",
      "(1504, 40)\n"
     ]
    }
   ],
   "source": [
    "GMM = {}\n",
    "UBM = {}\n",
    "for k, v in speakers_en.items():\n",
    "    GMM[k] = GaussianMixture(n_components= 5, covariance_type= 'diag')\n",
    "    UBM[k] = GaussianMixture(n_components= 5, covariance_type= 'diag')\n",
    "    print(v.shape)\n",
    "    GMM[k].fit(v)\n",
    "    other_v = []\n",
    "    for k1, v1 in speakers_en.items():\n",
    "        if(k1 != k):\n",
    "            other_v.append(v1)\n",
    "    other_v = np.concatenate(other_v)\n",
    "    UBM[k].fit(other_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For speaker hanqing\n",
      "accuracy is 0.44425817267393125\n",
      "For speaker jianzhi\n",
      "accuracy is 0.5574245939675174\n",
      "For speaker liuli\n",
      "accuracy is 0.6283244680851063\n",
      "For speaker Nick\n",
      "accuracy is 0.46453168044077137\n",
      "For speaker xiao\n",
      "accuracy is 0.5136303191489362\n"
     ]
    }
   ],
   "source": [
    "for k, v in speakers_ve.items():\n",
    "    print(\"For speaker {}\".format(k))\n",
    "    # print(GMM[k].score_samples(v))\n",
    "    x = GMM[k].score_samples(v) - UBM[k].score_samples(v)\n",
    "    total = 0 \n",
    "    correct = 0\n",
    "    for i in x:\n",
    "        if i > 0:\n",
    "            correct +=1 \n",
    "        total += 1\n",
    "    # Accuracy for every phoneme\n",
    "    print(\"accuracy is {}\".format(correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [dirs for dirs in os.listdir('.') if(dirs[-4:]==(\"-low\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hanqing-low', 'jianzhi-low', 'liuli-low', 'Nick-low', 'xiao-low']"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# Random select 2 as enrollment, to train GMM model\n",
    "def split(speaker_wavs):\n",
    "    random.shuffle(speaker_wavs)\n",
    "    # print(speaker_wavs)\n",
    "    enroll = speaker_wavs[:2]\n",
    "    verify = speaker_wavs[2:]\n",
    "    return enroll, verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers_en = {}\n",
    "speakers_ve = {}\n",
    "for idx,speaker in enumerate(dataset):\n",
    "    speaker_wavs = os.listdir(os.path.join('.', dataset[idx]))\n",
    "    speaker_label = dataset[idx][:-5]\n",
    "    enroll, verify = split(speaker_wavs)\n",
    "    en_mfccs = []\n",
    "    ve_mfccs = []\n",
    "    for en in enroll:\n",
    "        wav_path = os.path.join('.', dataset[idx], en)\n",
    "        mfcc = extractMFCC(wav_path,44100)\n",
    "        mfcc = mfcc - np.mean(mfcc, axis=0)\n",
    "        # print(mfcc.shape)\n",
    "        en_mfccs.append(mfcc)\n",
    "    speakers_en[speaker_label] = np.concatenate(en_mfccs, axis=0)\n",
    "    for ve in verify:\n",
    "        wav_path = os.path.join('.', dataset[idx], ve)\n",
    "        mfcc = extractMFCC(wav_path,44100)\n",
    "        mfcc = mfcc - np.mean(mfcc, axis=0)\n",
    "        # print(mfcc.shape)\n",
    "        ve_mfccs.append(mfcc)\n",
    "    speakers_ve[speaker_label] = np.concatenate(ve_mfccs, axis=0)\n",
    "#print(speakers_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(346, 40)\n",
      "(307, 40)\n",
      "(346, 40)\n",
      "(346, 40)\n",
      "(346, 40)\n"
     ]
    }
   ],
   "source": [
    "GMM = {}\n",
    "UBM = {}\n",
    "for k, v in speakers_en.items():\n",
    "    GMM[k] = GaussianMixture(n_components= 5, covariance_type= 'diag')\n",
    "    UBM[k] = GaussianMixture(n_components= 5, covariance_type= 'diag')\n",
    "    print(v.shape)\n",
    "    GMM[k].fit(v)\n",
    "    other_v = []\n",
    "    for k1, v1 in speakers_en.items():\n",
    "        if(k1 != k):\n",
    "            other_v.append(v1)\n",
    "    other_v = np.concatenate(other_v)\n",
    "    UBM[k].fit(other_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For speaker hanqin\n",
      "accuracy is 0.21242774566473988\n",
      "For speaker jianzh\n",
      "accuracy is 0.46181172291296624\n",
      "For speaker liul\n",
      "accuracy is 0.3627167630057804\n",
      "For speaker Nic\n",
      "accuracy is 0.25289017341040465\n",
      "For speaker xia\n",
      "accuracy is 0.5447976878612717\n"
     ]
    }
   ],
   "source": [
    "for k, v in speakers_ve.items():\n",
    "    print(\"For speaker {}\".format(k))\n",
    "    # print(GMM[k].score_samples(v))\n",
    "    x = GMM[k].score_samples(v) - UBM[k].score_samples(v)\n",
    "    total = 0 \n",
    "    correct = 0\n",
    "    for i in x:\n",
    "        if i > 0:\n",
    "            correct +=1 \n",
    "        total += 1\n",
    "    # Accuracy for every phoneme\n",
    "    print(\"accuracy is {}\".format(correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
